# -*- coding: utf-8 -*-
"""PCA - EXERCISE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q7BazBqdh70bBwqgCGtV1lkGuatR9TC0

# PCA - EXERCISE

###### The challenge:

In an astronomical observation, researchers used 17 different bands of the spectrum to analyze 4 celestial objects. Using the PCA -Principal component analysis find out which of the 4 celestial objects does not behave like a star.

### Import necessary libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.decomposition import PCA
import pylab as pl
import matplotlib.pyplot as plt
# %matplotlib inline

"""### Import data"""

data_bands = pd.read_csv('PCA_Data.csv',sep=';',index_col=0)

data_bands.head()

"""I will also use the dataframe in which the rows are the objects."""

data_bands.T

"""###### First we are going to visualize the values of the bands for each object in the following graph."""

pl.figure(figsize=((12, 5)))
for i, k in zip(data_bands.T.index,range(4)):
    l = pl.plot([j for j in range(1,18)], data_bands.T[data_bands.T.index==i].values.reshape(17,)+ 0.15 * k)
    c = l[0].get_color()
pl.ylim(0, 1500)
pl.xlabel('Banda')
pl.ylabel('Valor')
plt.legend(data_bands.T.index,prop={'size': 12})

"""The first thing is to visually search if one of the objects has values ​​in its bands different from the rest. It can be seen is that Object 2 has similar values to the rest with the exception of bands 1, 9 and 10. **This gives us the first clue that Object 2 is the one that does not behave like a star**.

### Correlation matrix

The next thing to do is look for the correlation of the Ojects taking the values of the bands. For this, the data will be used as follows.
"""

data_bands.head()

"""Pearson's correlation will be used."""

f, ax = plt.subplots(figsize=(8, 5))
matrix = np.triu(data_bands.corr(method='pearson'))
sns.heatmap(data_bands.corr(method='pearson'), annot=True, mask=matrix,cmap= 'coolwarm')

"""The previous graph shows the correlation between the objects. The highest correlation is between Object 1 and Object 4 with 0.99, that is, the values of their bands are very close (they are measurements of the same phenomenon). The lowest values (closest to 0) belong to object 2, it has a correlation 0.94 with Object 3 and 4; and 0.95 with object 1. This indicates that the values of the bands of objects 1,3 and 4 are very close and that the values of object 2 are more distant from the rest, which can be verified with the first graph. **This is an additional clue that tells us that Object 2 is the one that behaves differently.**

### Principal Component Analysis (PCA)

Now I have 17 bands per element, but I could have thousands, and what was done in the previous points could not be replicated or would be very expensive. Therefore PCA is used.

I will apply PCA, I will use the Sklearn library. The measurements are of the same phenomenon, so I am not going to standardize the data.

The data will be used as follows.
"""

X= data_bands.T
X.head()

"""I only have 4 rows (objects), therefore, at most we can generate 4 components."""

pca = PCA(n_components=4)
X_projected = pca.fit_transform(X)

X_projected

"""I will put the result in the following dataframe."""

data_bands_PCA = pd.DataFrame(data = X_projected, columns = ['PC 1', 'PC 2','PC 3', 'PC 4'], index=data_bands.T.index)
data_bands_PCA.head()

"""#### Explained Variance

To find out how many principal components to consider I am going to use the explained variance. This tells you how much information (variance) can be attributed to each of the principal components. It is important because when applying PCA information is lost (variance). I will use the attribute **"explained_variance_ratio_"**.
"""

[round(float(x)*100,2) for x in pca.explained_variance_ratio_]

"""The first principal component contains 67.44% of the variance and the second principal component contains 29.05% of the variance. Together, the two components contain 96.49% of the information.

I will use the first two principal components. I'm going to graph them.
"""

pc_1 = X_projected[:,0]
pc_2 = X_projected[:,1]

plt.figure()
plt.figure(figsize=(6,6))
plt.xticks(fontsize=12)
plt.yticks(fontsize=14)
plt.xlabel('Principal Component - 1',fontsize=20)
plt.ylabel('Principal Component - 2',fontsize=20)
plt.title("PCA - Bands",fontsize=20)
targets = ['Object 1', 'Object 2' ,'Object 3' ,'Object 4']
colors = ['g', 'r' ,'y','b']
for target, color in zip(targets,colors):
    indicesToKeep = data_bands.T.index == target
    plt.scatter(pc_1[indicesToKeep], pc_2[indicesToKeep], c = color, s = 50)
axes = plt.gca()
axes.set_xlim([-300,600])
axes.set_ylim([-300,600])
plt.legend(['Object 1', 'Object 2' ,'Object 3' ,'Object 4'],prop={'size': 15})

"""You can see that objects 1,3 and 4 are quite close to each other, and it is object 2 that has far values in the first two principal components. Therefore, we can conclude again that this **object 2 is the one that does not behave like the rest.**

If we look at the figure again, also note that only the first principal component can be used to reach the conclusion. The value of object two is quite far from the rest.
"""

data_bands_PCA[['PC 1']].T

"""In order to see which bands explain why the value of object 2 in the first component is distant, we will use the set of all eigenvectors. The "most important" bands will be those with a higher absolute value."""

pca.components_

"""I'm going to graph these values by principal component:"""

pl.figure(figsize=((12, 5)))
l = pl.plot([i for i in range(1,18)], pca.mean_ - 0.15)
c = l[0].get_color()
for i in range(4):
    l = pl.plot([i for i in range(1,18)], pca.components_[i] + 0.15 * i)
    c = l[0].get_color()
    pl.text(5, -0.01 + 0.15 * i, "component %i" % (i + 1), color=c)
pl.ylim(-0.8, 1)
pl.xlabel('Bans')
pl.ylabel('Value')

"""It can be seen that the bands with the greatest weight for the first component are bands 1, 9 and 10. These bands allow us to differentiate object 2 from the rest, which fits what was observed in the first graph. (Which is next)"""

pl.figure(figsize=((12, 5)))
for i, k in zip(data_bands.T.index,range(4)):
    l = pl.plot([j for j in range(1,18)], data_bands.T[data_bands.T.index==i].values.reshape(17,)+ 0.15 * k)
    c = l[0].get_color()
pl.ylim(0, 1500)
pl.xlabel('Banda')
pl.ylabel('Valor')
pl.title('Bands of the spectrum')
plt.legend(data_bands.T.index,prop={'size': 12})

"""#### In conclusion, celestial object 2 does not behave like a star."""